{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a93a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "\n",
    "<style>    \n",
    "    @import url(\"css/custom_styles.css\")\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bafcf8",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1>\n",
    "    Projet\n",
    "    </h1>\n",
    "    PlantVillage et Bag Of Visual Words\n",
    "    <br>\n",
    "    <br>\n",
    "    <br>\n",
    "    <br>\n",
    "    <b>Frédéric Champagne</b><br>\n",
    "    <b>Jean-Francois Gagnon</b><br>\n",
    "    <b>Michèle De la Sablonière</b><br>\n",
    "    <br>\n",
    "    420-A52\n",
    "    <br>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6ebc02",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0215affe",
   "metadata": {},
   "source": [
    "<font class=\"answer\">\n",
    "    \n",
    "Nous avons choisi la base de donnée [Plant Village](https://data.mendeley.com/datasets/tywbtsjrjv/1). Elle se compose de de plus de 60 000 images de feuilles de plante exhibant diverses maladies. Elles sont réparties en 38 differentes classes combiant espèce et maladie. L'objectif de ce projet est donc d'identifier la classe à partir de l'image d'origine. Pour ce faire, nous comptons utiliser la technique \"Bag of Visual Words\". Elle sera détaillée un peu plus bas dans le rapport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d914ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# imports utilitaires\n",
    "#\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#\n",
    "# imports faisant partie de nos propres modules\n",
    "# voir l'annexe pour plus de détails\n",
    "#\n",
    "\n",
    "import helpers as hlp\n",
    "import helpers.split as split\n",
    "import helpers.dataset.PlantVillage as pv\n",
    "import helpers.features as feat\n",
    "\n",
    "from helpers.jupyter import display_html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec93b72",
   "metadata": {},
   "source": [
    "# Prétraitement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682de01b",
   "metadata": {},
   "source": [
    "<font class=\"answer\">\n",
    "\n",
    "PlantVillage consiste en un fichier .zip contenant uniquement des images. L'information de classe est encodée dans les chemin des fichiers. Le format est:\n",
    "\n",
    "<br>\n",
    "<center>[Espece]__[Maladie]/[image]</center>\n",
    "    \n",
    "Nous avons élaborer un processus qui extrait et le normalise cette information. En effet, certains individus ne repectaient pas tout à fait le format attendu. Exemple de traitement:\n",
    "\n",
    "```python\n",
    "def _extract_dataframe(config, filename):\n",
    "    species_disease_pattern = re.compile(config.species_disease_re)\n",
    "    species_pattern = re.compile(config.species_re)\n",
    "\n",
    "    labels = filename.split(\"/\")[-2]\n",
    "    labels_match = species_disease_pattern.match(labels)\n",
    "    if labels_match is None:\n",
    "        return None\n",
    "\n",
    "    plant_species, plant_disease = labels_match.groups()\n",
    "\n",
    "    # some elements do not respect nomenclature\n",
    "    # found in litterature: fix it\n",
    "    species_match = species_pattern.match(plant_species)\n",
    "    if not species_match is None:\n",
    "        plant_species = config.label_separator.join(species_match.groups())\n",
    "\n",
    "    # some elements duplicate plant species within plan disease\n",
    "    # keep plant species only 1x\n",
    "    if plant_species in plant_disease:\n",
    "        label = plant_disease\n",
    "    else:\n",
    "        label = config.label_separator.join([plant_species,\n",
    "                                             plant_disease])\n",
    "```\n",
    "    \n",
    "Nous avons décortiqué la classe en sous composantes pour partager une information concise et uniforme à travers toutes les étapes de notre projet. L'index (voir exploration) nous sert d'identifiant unique. Les colonnes de notre dataframe sont:\n",
    "* species: Espèce de la plante\n",
    "* disease: Nom de la maladie\n",
    "* label: La classe normalisée (combine espèce et maladie)\n",
    "* image_path: Chemin de l'image correspondante\n",
    "    \n",
    "Finalement, toutes les images ont la même dimension. A savoir 256x256."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba53687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# parametres configurant notre pipeline\n",
    "#\n",
    "configs = hlp.get_configs(\"config_overrides.json\")\n",
    "\n",
    "#\n",
    "# obtenir le dataset PlantVillage\n",
    "#\n",
    "pv_dataset = pv.load(configs.plant_village)\n",
    "pv_dataframe = pv_dataset.dataframe\n",
    "\n",
    "display_html(f\"<b>Nombre d'individus</b>: {pv_dataframe.shape[0]}\")\n",
    "display(pv_dataframe.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e527b6",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab1b6b9",
   "metadata": {},
   "source": [
    "## Question 1 et 2\n",
    "\n",
    "**Identifier d’abord les classes disponibles dans le dataset que vous avez choisi. Procéder à une exploration du dataset et identifier des valeurs manquantes, inconnues, etc. Procéder au remplacement de ces valeurs s’il y’a lieu.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b6563c",
   "metadata": {},
   "source": [
    "<font class=\"answer\">\n",
    "\n",
    "Nous savons que nous n'avons pas de valeurs manquantes ni inconnues de par notre prétraitement, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedd24f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pv_dataframe[\"label\"].unique()\n",
    "labels.sort()\n",
    "display_html(f\"<b>Modalités des classes</b>: {len(labels)}\")\n",
    "display(list(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937b002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "species = pv_dataframe[\"species\"].unique()\n",
    "species.sort()\n",
    "display_html(f\"<b>Modalites des espèces</b>: {species.size}\")\n",
    "display(list(species))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70046781",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# distribution des classes\n",
    "#\n",
    "FIGSIZE = (10, 4)\n",
    "\n",
    "disease_count = pv_dataframe[\"label\"].value_counts()\n",
    "disease_count.sort_values(inplace=True, ascending=False)\n",
    "\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "disease_count.plot.bar(title=\"Effectifs des classes\", ylabel=\"count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292e2f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# relation species/label\n",
    "#\n",
    "doi = pv_dataframe[[\"label\", \"species\"]]\n",
    "\n",
    "disease_samples_per_species = doi.groupby(\"species\") \\\n",
    "                                 .count() \\\n",
    "                                 .rename(columns={\"label\": \"effectif\"})\n",
    "disease_samples_per_species.sort_values(\"effectif\", inplace=True, ascending=False)\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "disease_samples_per_species.plot.bar(ax=plt.gca(), \n",
    "                                     xlabel=\"\", \n",
    "                                     ylabel=\"Effectif\")\n",
    "\n",
    "plt.title(\"Effectif de chaque espèces\", y=1.025)\n",
    "plt.show()\n",
    "\n",
    "display( disease_samples_per_species.T )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c17923",
   "metadata": {},
   "source": [
    "<font class=\"answer\">\n",
    "On observe qu'il y a un débalancement dans la répartition des classes et des espèces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86358e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# relation healthy et autres maladies\n",
    "#\n",
    "healthy_crit = doi[\"label\"].str.contains(\"healthy\")\n",
    "\n",
    "healthy = doi[healthy_crit]\n",
    "healthy = healthy \\\n",
    "            .groupby(\"species\") \\\n",
    "            .count() \\\n",
    "            .rename(columns={\"label\": \"healthy\"})\n",
    "\n",
    "not_healthy = doi[ ~healthy_crit ]\n",
    "not_healthy = not_healthy \\\n",
    "                .groupby(\"species\") \\\n",
    "                .count() \\\n",
    "                .rename(columns={\"label\": \"not healthy\"})\n",
    "\n",
    "healthy_vs_other_per_species = pd.merge(healthy, \n",
    "                                        not_healthy,\n",
    "                                        how=\"outer\",\n",
    "                                        on=\"species\")\n",
    "\n",
    "# pour faciliter la comparison, garder le meme ordre que disease_samples_per_species\n",
    "healthy_vs_other_per_species = healthy_vs_other_per_species \\\n",
    "                                   .reindex(disease_samples_per_species \\\n",
    "                                   .index.to_list())\n",
    "\n",
    "fig = plt.figure(figsize=(7, 4))\n",
    "fig.suptitle(\"Effectifs des classes par espèce de plante\")\n",
    "\n",
    "healthy_vs_other_per_species.plot.bar(ax=plt.gca(),\n",
    "                                      stacked=True, \n",
    "                                      xlabel=\"\",\n",
    "                                      ylabel=\"count\")\n",
    "plt.title(\"healthy vs not healthy\", y=1.025)\n",
    "plt.show()\n",
    "\n",
    "display(healthy_vs_other_per_species.replace(np.nan, 0).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51931ece",
   "metadata": {},
   "source": [
    "<font class=\"answer\">\n",
    "\n",
    "TODO: reformuler par objectif de classifier\n",
    "    \n",
    "Nous désirons ignorer les espèces qui ne sont pas représentées dans les deux momdalités (healthy et not healthy). Blueberry, Soybean, Rasberry, Squash et Orange ont donc été écarté."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbba0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = [\"Blueberry\", \"Soybean\", \"Rasberry\", \"Squash\", \"Orange\"]\n",
    "to_remove = pv_dataframe[\"species\"].isin(to_remove)\n",
    "\n",
    "pv_dataframe_filtered = pv_dataframe[~to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c3601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploration des effectifs de chaque species\n",
    "def composante(bd, fruit):\n",
    "    fruit_crit = bd[\"label\"].str.contains(fruit)\n",
    "    fruit1 = bd[fruit_crit]\n",
    "\n",
    "    fruit_count = fruit1[\"label\"].value_counts()\n",
    "    fruit_count.sort_values()\n",
    "\n",
    "    print(\"Les composantes de\", fruit, \"sont\")\n",
    "    display(fruit_count.to_frame())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67529af",
   "metadata": {},
   "outputs": [],
   "source": [
    "composante(pv_dataframe_filtered, \"Tomato\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3a14ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "composante(pv_dataframe_filtered, \"Apple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd3cfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "composante(pv_dataframe_filtered, \"Cherry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93ee421",
   "metadata": {},
   "outputs": [],
   "source": [
    "composante(pv_dataframe_filtered, \"Corn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e653a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "composante(pv_dataframe_filtered, \"Grape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253eaa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "composante(pv_dataframe_filtered, \"Peach\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d61b767",
   "metadata": {},
   "outputs": [],
   "source": [
    "composante(pv_dataframe_filtered, \"Pepper,_bell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0901cfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "composante(pv_dataframe_filtered, \"Potato\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdcdfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "composante(pv_dataframe_filtered, \"Strawberry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00382400",
   "metadata": {},
   "source": [
    "Comme nous avons une grosse base de données nous avons décidé, pour réduire le temps d'exécution et rendre le travail plus facile, de choisir une seule species qui contient plus qu'une maladie et des groupes assez équilibré et des images significatives. Nous allons donc choisir entre Apple, Corn, Grape et Potato. Pour éclairer notre choix nous allons regarder les photos de plus près. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d637383b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def affichage_image(bd, fruit):\n",
    "    fruit_crit = bd[\"label\"].str.contains(fruit)\n",
    "    fruit1 = bd[fruit_crit]\n",
    "    SAMPLES_GRID = (5, 5)\n",
    "\n",
    "    random.seed(42)\n",
    "    sample_indices = random.sample(range(fruit1.shape[0]),\n",
    "                                   SAMPLES_GRID[0] * SAMPLES_GRID[1])\n",
    "    sample_indices.sort()\n",
    "\n",
    "    samples = fruit1.iloc[sample_indices]\n",
    "\n",
    "    FIGSIZE = (10, 10)\n",
    "\n",
    "    fig = plt.figure(figsize=FIGSIZE)\n",
    "\n",
    "    for i, (sample_index, sample_data) in enumerate(samples.iterrows()):\n",
    "        plt.subplot(SAMPLES_GRID[0], SAMPLES_GRID[1], i + 1)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        species = sample_data['species']\n",
    "        disease = pv.attribute_prettify(species, sample_data['label'])\n",
    "\n",
    "        image = pv_dataset.get_image(sample_index)\n",
    "\n",
    "        plt.title(f\"{species}\\n{disease}\")\n",
    "        plt.imshow(image)\n",
    "        plt.gca().title.set_size(10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(hspace=0.5, top=0.8)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d16f54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "affichage_image(df, \"Apple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2326ba09",
   "metadata": {},
   "outputs": [],
   "source": [
    "affichage_image(df, \"Corn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8452e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "affichage_image(df, \"Grape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73803c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "affichage_image(df, \"Potato\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8143f76",
   "metadata": {},
   "source": [
    "En regardant les photos de plus près nous avons constaté que pour les species Apple,Corn et Potato les différences entre les photos des différentes maladies sont moins significatives que pour Grape c'est pourquoi nous avons choisi de garder celle-ci. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d48b4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "searchfor = [\"Grape\"]\n",
    "group_sel = group_selection(df1, searchfor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1115405",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Équilibrage des groupes de Grape\n",
    "\n",
    "x1 = group_sel\n",
    "y1 = group_sel[\"label\"].values.reshape(-1, 1)\n",
    "\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "x_bal, y_bal = rus.fit_resample(x1, y1)\n",
    "\n",
    "x = x_bal[\"label\"]\n",
    "\n",
    "print(x_bal[\"label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd35036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation de deux ensembles train/test pour le reste des étapes\n",
    "x_train, x_test = train_test_split(\n",
    "    x,  stratify=x, test_size=0.2, random_state=44)\n",
    "\n",
    "x_train = x_train.index.to_list()\n",
    "x_test = x_test.index.to_list()\n",
    "split.save(configs.split, x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7727a0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "\n",
    "<style>    \n",
    "    @import url(\"css/custom_styles.css\")\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda3f09b",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "[Plant Village](https://data.mendeley.com/datasets/tywbtsjrjv/1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28817d49",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "Dans cette base de données, il y a 39 differentes classes d'image de feuilles. La base de donnée contient 61,486 images.\n",
    "\n",
    "Les classes sont: \n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"columns_2\">\n",
    "    \n",
    "1. Apple_scab\n",
    "2. Apple_black_rot\n",
    "3. Apple_cedar_apple_rust\n",
    "4. Apple_healthy\n",
    "5. Background_without_leaves\n",
    "6. Blueberry_healthy\n",
    "7. Cherry_powdery_mildew\n",
    "8. Cherry_healthy\n",
    "9. Corn_gray_leaf_spot\n",
    "10. Corn_common_rust\n",
    "11. Corn_northern_leaf_blight\n",
    "12. Corn_healthy\n",
    "13. Grape_black_rot\n",
    "14. Grape_black_measles\n",
    "15. Grape_leaf_blight\n",
    "16. Grape_healthy\n",
    "17. Orange_haunglongbing\n",
    "18. Peach_bacterial_spot\n",
    "19. Peach_healthy\n",
    "20. Pepper_bacterial_spot\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"columns_2\">\n",
    "    \n",
    "21. Pepper_healthy\n",
    "22. Potato_early_blight\n",
    "23. Potato_healthy\n",
    "24. Potato_late_blight\n",
    "25. Raspberry_healthy\n",
    "26. Soybean_healthy\n",
    "27. Squash_powdery_mildew\n",
    "28. Strawberry_healthy\n",
    "29. Strawberry_leaf_scorch\n",
    "30. Tomato_bacterial_spot\n",
    "31. Tomato_early_blight\n",
    "32. Tomato_healthy\n",
    "33. Tomato_late_blight\n",
    "34. Tomato_leaf_mold\n",
    "35. Tomato_septoria_leaf_spot\n",
    "36. Tomato_spider_mites_two-spotted_spider_mite\n",
    "37. Tomato_target_spot\n",
    "38. Tomato_mosaic_virus\n",
    "39. Tomato_yellow_leaf_curl_virus\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c33104",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#\n",
    "# import utilitaires\n",
    "#\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import helpers as hlp\n",
    "import helpers.split as split\n",
    "import helpers.dataset.PlantVillage as pv\n",
    "import helpers.features as feat\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from helpers.jupyter import display_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd16410",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# parametres\n",
    "#\n",
    "configs = hlp.get_configs(\"config_overrides.json\")\n",
    "\n",
    "#\n",
    "# obtenir le dataset PlantVillage\n",
    "#\n",
    "with hlp.Profile() as load_profile:\n",
    "    pv_dataset = pv.load(configs.plant_village)\n",
    "    pv_dataframe = pv_dataset.dataframe\n",
    "    \n",
    "print(f\"Loading dataset:\", load_profile.round_duration(), \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad07b69d",
   "metadata": {},
   "source": [
    "# asdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c235507",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfe3cfc",
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "display_html(f\"<b>{configs.plant_village.install_path}</b> - data {pv_dataframe.shape}\")\n",
    "display(pv_dataframe.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c262990",
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "display_html(f\"<b>{configs.plant_village.install_path}</b> - info\")\n",
    "pv_dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa57995",
   "metadata": {},
   "outputs": [],
   "source": [
    "species = pv_dataframe[\"species\"].unique()\n",
    "species.sort()\n",
    "display_html(f\"<b>Modalites de 'species'</b> - count: {species.size}\")\n",
    "display(list(species))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ed96b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pv_dataframe[\"label\"].unique()\n",
    "labels.sort()\n",
    "display_html(f\"<b>Modalites de 'label'</b> - count: {len(labels)}\")\n",
    "display(list(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c9f74a",
   "metadata": {},
   "source": [
    "<font class=\"answer\">\n",
    "\n",
    "**Notes**\n",
    "* Background_without_leaves a été intentionellement enlevé\n",
    "* Les modalités semblent avoir evoluées par rapport à la liste citée ci-haut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402aa8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# distribution de label\n",
    "#\n",
    "FIGSIZE = (10, 4)\n",
    "\n",
    "disease_count = pv_dataframe[\"label\"].value_counts()\n",
    "disease_count.sort_values(inplace=True, ascending=False)\n",
    "\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "disease_count.plot.bar(title=\"Effectifs de 'label'\",\n",
    "                       ylabel=\"count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0953bb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification des valeurs manquantes\n",
    "\n",
    "display(pv_dataframe[pv_dataframe.isna().any(\n",
    "    axis=1)].style.highlight_null('green'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dd0913",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# relation species/label\n",
    "#\n",
    "doi = pv_dataframe[[\"label\", \"species\"]]\n",
    "\n",
    "disease_samples_per_species = doi.groupby(\"species\").count()\n",
    "disease_samples_per_species.sort_values(\"label\", inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f11ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_crit = doi[\"label\"].str.contains(\"healthy\")\n",
    "\n",
    "healthy = doi[healthy_crit]\n",
    "healthy = healthy \\\n",
    "            .groupby(\"species\") \\\n",
    "            .count() \\\n",
    "            .rename(columns={\"label\": \"healthy\"})\n",
    "\n",
    "not_healthy = doi[ ~healthy_crit ]\n",
    "not_healthy = not_healthy \\\n",
    "                .groupby(\"species\") \\\n",
    "                .count() \\\n",
    "                .rename(columns={\"label\": \"autres\"})\n",
    "\n",
    "healthy_vs_other_per_species = pd.merge(healthy, \n",
    "                                        not_healthy,\n",
    "                                        how=\"outer\",\n",
    "                                        on=\"species\")\n",
    "\n",
    "# pour faciliter la comparison, garder le meme ordre que disease_samples_per_species\n",
    "healthy_vs_other_per_species = healthy_vs_other_per_species \\\n",
    "                                   .reindex(disease_samples_per_species \\\n",
    "                                   .index.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0302f474",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=FIGSIZE)\n",
    "fig.suptitle(\"Effectifs de 'label' par espece de plante\")\n",
    "\n",
    "plt.subplot(121)\n",
    "healthy_vs_other_per_species.plot.bar(ax=plt.gca(),\n",
    "                                      stacked=True, \n",
    "                                      xlabel=\"\",\n",
    "                                      ylabel=\"count\")\n",
    "plt.title(\"'healthy' vs autres\", y=1.025)\n",
    "\n",
    "plt.subplot(122)\n",
    "_, _, pcts = plt.pie(x=disease_samples_per_species.values.flatten(),\n",
    "                     labels=disease_samples_per_species.index.values,\n",
    "                     autopct='%.0f%%',\n",
    "                     radius=1.25,\n",
    "                     wedgeprops={'linewidth': 1.0, \n",
    "                                 'edgecolor': 'white'})\n",
    "plt.title(\"Toute maladies confondues\", y=1.025)\n",
    "plt.setp(pcts, color='white')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7f128c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# visualiser quelques images\n",
    "#\n",
    "SAMPLES_GRID = (2, 7)\n",
    "\n",
    "# selectionner quelques images aleatoirement (mais pas trop aleatoire)\n",
    "random.seed(42)\n",
    "sample_indices = random.sample(range(pv_dataframe.shape[0]), \n",
    "                               SAMPLES_GRID[0] * SAMPLES_GRID[1])\n",
    "sample_indices.sort()\n",
    "\n",
    "samples = pv_dataframe.iloc[sample_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650fbeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIGSIZE = (10, 6.5)\n",
    "\n",
    "fig = plt.figure(figsize=FIGSIZE)\n",
    "\n",
    "for i, (sample_index, sample_data) in enumerate(samples.iterrows()):\n",
    "    plt.subplot(SAMPLES_GRID[0], SAMPLES_GRID[1], i + 1)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    species = sample_data['species']\n",
    "    disease = pv.attribute_prettify(species, sample_data['disease'])\n",
    "        \n",
    "    image = pv_dataset.get_image(sample_index)\n",
    "    \n",
    "    plt.title(f\"{species}\\n{disease}\")    \n",
    "    plt.imshow(image)\n",
    "    plt.gca().title.set_size(10)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.subplots_adjust(hspace=0.5, top=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84df9001",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploration des species\n",
    "df = pv_dataset.dataframe[[\"label\", \"species\"]]\n",
    "\n",
    "nbEspece = df.groupby(\"species\").count()\n",
    "print(\"Nombres d'individus dans chaque 'species'\",nbEspece)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ff16c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_crit = df[\"label\"].str.contains(\"healthy\")\n",
    "healthy = df[healthy_crit]\n",
    "healthy = healthy.groupby(\"species\").count()\n",
    "\n",
    "not_healthy = df[~healthy_crit]\n",
    "not_healthy = not_healthy.groupby(\"species\").count()\n",
    "print(\"Nombre d'individus dans les 'species' Healthy:\\n\",healthy)\n",
    "print(\"Nombre d'individus dans les 'species' qui sont des maladies:\\n\",not_healthy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646d985a",
   "metadata": {},
   "source": [
    "Nous avons effectué une première sélection en enlevant les species qui ne sont pas représenté dans les deux catégories (healthy et not healthy). Blueberry, Soybean, Rasberry, Squash et Orange ont été enlevé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab31f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_selection(df, searchfor):\n",
    "    crit = '|'.join(searchfor)\n",
    "    return df[df[\"label\"].str.contains(crit)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147c0d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pv_dataset.dataframe\n",
    "\n",
    "searchfor = [\"Apple\", \"Cherry\", \"Corn\", \"Grape\", \"Peach\",\n",
    "             \"Pepper,_bell\", \"Potato\", \"Strawberry\", \"Tomato\"]\n",
    "group_sel = group_selection(df1, searchfor)\n",
    "# in\n",
    "sel1 = group_sel.groupby(\"species\").count()\n",
    "\n",
    "print(\"Species restant dans la première sélection avec leur effectifs\\n\", sel1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091a3b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploration des effectifs de chaque species\n",
    "def composante(bd, fruit):\n",
    "    fruit_crit = bd[\"label\"].str.contains(fruit)\n",
    "    fruit1 = bd[fruit_crit]\n",
    "\n",
    "    fruit_count = fruit1[\"label\"].value_counts()\n",
    "    fruit_count.sort_values\n",
    "\n",
    "    print(\"Les composantes de\", fruit, \"sont :\\n\", fruit_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8642d49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "composante(df, \"Tomato\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce05ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "composante(df, \"Apple\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92380c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "composante(df, \"Cherry\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d2a34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "composante(df, \"Corn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a700d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "composante(df, \"Grape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0833f879",
   "metadata": {},
   "outputs": [],
   "source": [
    "composante(df, \"Peach\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f0eca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "composante(df, \"Pepper,_bell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d065fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "composante(df, \"Potato\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea87ddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "composante(df, \"Strawberry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0898d1",
   "metadata": {},
   "source": [
    "Comme nous avons une grosse base de données nous avons décidé, pour réduire le temps d'exécution et rendre le travail plus facile, de choisir une seule species qui contient plus qu'une maladie et des groupes assez équilibré et des images significatives. Nous allons donc choisir entre Apple, Corn, Grape et Potato. Pour éclairer notre choix nous allons regarder les photos de plus près. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f031ce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def affichage_image(bd, fruit):\n",
    "    fruit_crit = bd[\"label\"].str.contains(fruit)\n",
    "    fruit1 = bd[fruit_crit]\n",
    "    SAMPLES_GRID = (5, 5)\n",
    "\n",
    "    random.seed(42)\n",
    "    sample_indices = random.sample(range(fruit1.shape[0]),\n",
    "                                   SAMPLES_GRID[0] * SAMPLES_GRID[1])\n",
    "    sample_indices.sort()\n",
    "\n",
    "    samples = fruit1.iloc[sample_indices]\n",
    "\n",
    "    FIGSIZE = (10, 10)\n",
    "\n",
    "    fig = plt.figure(figsize=FIGSIZE)\n",
    "\n",
    "    for i, (sample_index, sample_data) in enumerate(samples.iterrows()):\n",
    "        plt.subplot(SAMPLES_GRID[0], SAMPLES_GRID[1], i + 1)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        species = sample_data['species']\n",
    "        disease = pv.attribute_prettify(species, sample_data['label'])\n",
    "\n",
    "        image = pv_dataset.get_image(sample_index)\n",
    "\n",
    "        plt.title(f\"{species}\\n{disease}\")\n",
    "        plt.imshow(image)\n",
    "        plt.gca().title.set_size(10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(hspace=0.5, top=0.8)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5849b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "affichage_image(df, \"Apple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16e0e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "affichage_image(df, \"Corn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b1d333",
   "metadata": {},
   "outputs": [],
   "source": [
    "affichage_image(df, \"Grape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ec67d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "affichage_image(df, \"Potato\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cae9e74",
   "metadata": {},
   "source": [
    "En regardant les photos de plus près nous avons constaté que pour les species Apple,Corn et Potato les différences entre les photos des différentes maladies sont moins significatives que pour Grape c'est pourquoi nous avons choisi de garder celle-ci. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8a1a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "searchfor = [\"Grape\"]\n",
    "group_sel = group_selection(df1, searchfor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687a35f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Équilibrage des groupes de Grape\n",
    "\n",
    "x1 = group_sel\n",
    "y1 = group_sel[\"label\"].values.reshape(-1, 1)\n",
    "\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "x_bal, y_bal = rus.fit_resample(x1, y1)\n",
    "\n",
    "x = x_bal[\"label\"]\n",
    "\n",
    "print(x_bal[\"label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685138b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation de deux ensembles train/test pour le reste des étapes\n",
    "x_train, x_test = train_test_split(\n",
    "    x,  stratify=x, test_size=0.2, random_state=44)\n",
    "\n",
    "x_train = x_train.index.to_list()\n",
    "x_test = x_test.index.to_list()\n",
    "split.save(configs.split, x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f0ac2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#\n",
    "# import utilitaires\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import helpers as hlp\n",
    "import helpers.dataset.PlantVillage as pv\n",
    "import helpers.features as feat\n",
    "\n",
    "from pathlib import Path\n",
    "from rembg import remove, new_session\n",
    "import zipfile\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23597bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# parametres\n",
    "#\n",
    "configs = hlp.get_configs(\"config_overrides.json\")\n",
    "\n",
    "#\n",
    "# obtenir le dataset PlantVillage\n",
    "#\n",
    "pv_dataset = pv.load(configs.plant_village)\n",
    "\n",
    "if pv_dataset is None:\n",
    "    print(\"Invalid dataset\")\n",
    "else:\n",
    "    pv_dataframe = pv_dataset.dataframe\n",
    "\n",
    "print(\"PlantVillage\", pv_dataframe.shape)\n",
    "display( pv_dataframe.head() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa45db0",
   "metadata": {},
   "source": [
    "Etant donne que les features vont être utilisées tout au long de notre pipeline, nous processons tous le dataset une seul fois et mettons en cache les résultats. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f000451b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.exists(\"dataset/Plant_leaf_diseases_dataset_with_augmentation\"):\n",
    "#     with zipfile.ZipFile(\"dataset/Plant_leaf_diseases_dataset_with_augmentation.zip\", 'r') as zip_ref:\n",
    "#         zip_ref.extractall(\"dataset/Plant_leaf_diseases_dataset_with_augmentation\")\n",
    "# '''\n",
    "# session = new_session()\n",
    "\n",
    "# for root, dirs, files in os.walk('dataset/Plant_leaf_diseases_dataset_with_augmentation'):\n",
    "\n",
    "#     for file in Path(root).glob('*.JPG'):\n",
    "#         input_path = str(file)\n",
    "#         output_path = str(file.parent / (file.stem + \".out.png\"))\n",
    "\n",
    "#         with open(input_path, 'rb') as i:\n",
    "#             with open(output_path, 'wb') as o:\n",
    "#                 input = i.read()\n",
    "#                 output = remove(input, session=session)\n",
    "#                 o.write(output)\n",
    "#                 time.sleep(0.2)\n",
    "# '''                \n",
    "# print(pv_dataset.get_image(60342))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529cc153",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# features orb\n",
    "#\n",
    "\n",
    "# pour debugger, s'assurer que le fichier de features \n",
    "# est detruit a chaque execution de la cellule\n",
    "if \"orb_features\" in locals():\n",
    "    del orb_features\n",
    "\n",
    "with hlp.Profile() as orb_loading:\n",
    "    #\n",
    "    # obtenir les orb features pour chaque image du dataset\n",
    "    #\n",
    "    orb_iter = feat.DatasetIter(pv_dataset, \n",
    "                                pv_dataframe[\"image_path\"].items(),\n",
    "                                pv_dataframe.shape[0])\n",
    "\n",
    "    # la premiere execution va mettre en cache les resultats\n",
    "    orb_features = feat.load(configs.orb, orb_iter)\n",
    "\n",
    "print(f\"ORB loading:\", orb_loading.round_duration(), \"s\")\n",
    "print(\"ORB features\", orb_features.features.shape)\n",
    "print(\"ORB keypoints\", orb_features.key_points.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bccff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# features sift\n",
    "#\n",
    "\n",
    "# pour debugger, s'assurer que le fichier de features \n",
    "# est detruit a chaque execution de la cellule\n",
    "if \"sift_features\" in locals():\n",
    "    del sift_features\n",
    "\n",
    "with hlp.Profile() as sift_loading:\n",
    "    #\n",
    "    # obtenir les sift features pour chaque image du dataset\n",
    "    #\n",
    "    sift_iter = feat.DatasetIter(pv_dataset, \n",
    "                                 pv_dataframe[\"image_path\"].items(),\n",
    "                                 pv_dataframe.shape[0])\n",
    "\n",
    "    # la premiere execution va mettre en cache les resultats\n",
    "    sift_features = feat.load(configs.sift, sift_iter)\n",
    "\n",
    "print(f\"SIFT loading:\", sift_loading.round_duration(), \"s\")\n",
    "print(\"SIFT features\", sift_features.features.shape)\n",
    "print(\"SIFT keypoints\", sift_features.key_points.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75c751c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES_GRID = (2, 4)\n",
    "FIGSIZE = (10, SAMPLES_GRID[0] * 3.5)\n",
    "\n",
    "def affiche_image(features, indices):\n",
    "    dataset_iter = feat.DatasetIter(pv_dataset, \n",
    "                                    pv_dataframe.loc[indices, \"image_path\"].items())\n",
    "\n",
    "    _, axes = plt.subplots(SAMPLES_GRID[0], SAMPLES_GRID[1], figsize=FIGSIZE)\n",
    "    for ax, \\\n",
    "       (image_index, \\\n",
    "        _, \\\n",
    "        key_points_count, \\\n",
    "        key_points_image) in zip(axes.flatten(), feat.key_points_iter(features, dataset_iter)):    \n",
    "        if key_points_image is None:\n",
    "            continue\n",
    "        plt.sca(ax)\n",
    "\n",
    "        species, disease = pv_dataframe.loc[image_index, [\"species\", \"disease\"]]\n",
    "        disease = pv.attribute_prettify(species, disease)\n",
    "        title = \"\\n\".join([species, disease, str(key_points_count)])\n",
    "\n",
    "        plt.title(title)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(key_points_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2f2787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selectionner quelques images aleatoirement\n",
    "random.seed(55)\n",
    "indices = random.sample(range(pv_dataframe.shape[0]), SAMPLES_GRID[0] * SAMPLES_GRID[1])\n",
    "indices.sort()\n",
    "\n",
    "\n",
    "#\n",
    "# visualiser quelques orb keypoints\n",
    "#\n",
    "affiche_image(orb_features, indices)\n",
    "\n",
    "plt.suptitle(\"ORB keypoints\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#\n",
    "# visualiser quelques sift keypoints (les memes que orb)\n",
    "#\n",
    "affiche_image(sift_features, indices)\n",
    "\n",
    "plt.suptitle(\"SIFT keypoints\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5840ef34",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#\n",
    "# import utilitaires\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import helpers as hlp\n",
    "import helpers.split as split\n",
    "import helpers.visual_words as vw\n",
    "import helpers.features as feat\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87afbd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# parametres\n",
    "#\n",
    "configs = hlp.get_configs(\"config_overrides.json\")\n",
    "\n",
    "#\n",
    "# train/test sets\n",
    "# \n",
    "train, test = split.load(configs.split)\n",
    "print(\"Train size\", len(train))\n",
    "print(\"Test size\", len(test))\n",
    "print()\n",
    "\n",
    "#\n",
    "# features orb\n",
    "#\n",
    "# mettre a jour train/test set features\n",
    "configs.orb.read_only = False\n",
    "orb_features = feat.load(configs.orb, None)\n",
    "if configs.orb.force_generate or orb_features.train_features is None:\n",
    "    feat.update_train_test(orb_features, train, test)\n",
    "\n",
    "print(\"ORB features\", orb_features.features.shape)\n",
    "print(\"ORB train features\", orb_features.train_features.shape)\n",
    "print(\"ORB test features\", orb_features.test_features.shape)\n",
    "print()\n",
    "\n",
    "#\n",
    "# features sift\n",
    "#\n",
    "configs.sift.read_only = False\n",
    "sift_features = feat.load(configs.sift, None)\n",
    "if configs.sift.force_generate or sift_features.train_features is None:\n",
    "    feat.update_train_test(sift_features, train, test)\n",
    "\n",
    "print(\"SIFT features\", sift_features.features.shape)\n",
    "print(\"SIFT train features\", sift_features.train_features.shape)\n",
    "print(\"SIFT test features\", sift_features.test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950bbfa6",
   "metadata": {},
   "source": [
    "Etant donnée que les descripteurs des images représentent un apport important à la quantité de données à traiter (14 382 049 de descripteurs pour 3 711 images, plus de 3 ordres de grandeurs en quantité), nous voulons optimiser cet impact. Une analyse PCA nous permettra de les transformer pour éventuellment réduire leurs dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea41efeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_pca(x):\n",
    "    pca_pipeline = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                             (\"pca\", PCA(svd_solver=\"full\"))])\n",
    "    pca_pipeline.fit(x)\n",
    "    return pca_pipeline\n",
    "\n",
    "def features_pca_analysis(pca_model, title_prefix, threshold=None, figsize=(5, 3)):\n",
    "    var_ratio = pca_model.explained_variance_ratio_\n",
    "    inertia = np.cumsum(var_ratio)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(range(inertia.shape[0]), inertia, marker=\".\")\n",
    "    if not threshold is None:\n",
    "        plt.axhline(y=threshold, color=\"red\", linestyle=\"-\")\n",
    "    plt.grid()\n",
    "    plt.title(f\"{title_prefix}\\n% variance expliquée vs # composantes\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f069df",
   "metadata": {},
   "outputs": [],
   "source": [
    "with hlp.Profile() as orb_features_pca_profile:\n",
    "    orb_features_pca = features_pca(orb_features.train_features)\n",
    "\n",
    "print(\"ORB Features PCA:\", orb_features_pca_profile.round_duration(), \"s\")\n",
    "print(\"ORB Features PCA valeurs propres:\")\n",
    "print(orb_features_pca[\"pca\"].explained_variance_)\n",
    "\n",
    "features_pca_analysis(orb_features_pca[\"pca\"], \"ORB\", 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cdf623",
   "metadata": {},
   "source": [
    "Le graphique précédant n'exhibe pas de \"coude franc\". Nous établisons donc un seuil à 95% ce qui permet de garder 26 composantes sur les 32 d'origine. Ce paramètre est intégré dans notre pipeline dans l'étape suivante via les fichiers de configuration.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b645b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATTENTION: cette etape peut etre longue a la 1e execution\n",
    "#            elle est sans feedback visuel, soyez patient\n",
    "with hlp.Profile() as orb_bovw_profile:\n",
    "    orb_bovw = vw.load_bovw(configs.orb_bovw, orb_features.train_features)\n",
    "\n",
    "print(\"ORB BoVW loading:\", orb_bovw_profile.round_duration(), \"s\")\n",
    "print(\"ORB BoVW clusters:\", orb_bovw.cluster_centers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3133d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with hlp.Profile() as sift_features_pca_profile:\n",
    "    sift_features_pca = features_pca(sift_features.train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e942e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ORB Features PCA:\", sift_features_pca_profile.round_duration(), \"s\")\n",
    "print(\"ORB Features PCA valeurs propres:\")\n",
    "print(sift_features_pca[\"pca\"].explained_variance_)\n",
    "\n",
    "features_pca_analysis(sift_features_pca[\"pca\"], \"SIFT\", 0.95, (8, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d71d35",
   "metadata": {},
   "source": [
    "De la même manière que précédement, nous établisons donc un seuil à 95% ce qui permet de garder 80 composantes sur les 128 d'origine. Ce paramètre est intégré dans notre pipeline dans l'étape suivante via les fichiers de configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049fef0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATTENTION: cette etape peut etre longue a la 1e execution\n",
    "#            elle est sans feedback visuel, soyez patient\n",
    "with hlp.Profile() as sift_bovw_profile:\n",
    "    sift_bovw = vw.load_bovw(configs.sift_bovw, sift_features.train_features)\n",
    "\n",
    "print(\"SIFT BoVW loading:\", sift_bovw_profile.round_duration(), \"s\")\n",
    "print(\"SIFT BoVW clusters:\", sift_bovw.cluster_centers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7c9221",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# import utilitaires\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import helpers as hlp\n",
    "import helpers.split as split\n",
    "import helpers.dataset.PlantVillage as pv\n",
    "import helpers.features as feat\n",
    "import helpers.visual_words as vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7ef956",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# parametres\n",
    "#\n",
    "configs = hlp.get_configs(\"config_overrides.json\")\n",
    "\n",
    "# pour update tf-idf\n",
    "configs.orb_bovw.read_only = False\n",
    "configs.sift_bovw.read_only = False\n",
    "\n",
    "\n",
    "#\n",
    "# dataset PlantVillage\n",
    "#\n",
    "pv_dataset = pv.load(configs.plant_village)\n",
    "pv_dataframe = pv_dataset.dataframe\n",
    "\n",
    "print(\"Dataset\", pv_dataframe.shape)\n",
    "print()\n",
    "\n",
    "\n",
    "#\n",
    "# train/test\n",
    "#\n",
    "train, test = split.load(configs.split)\n",
    "\n",
    "print(\"Train size:\", len(train))\n",
    "print(\"Test size:\", len(test))\n",
    "print()\n",
    "\n",
    "#\n",
    "# orb\n",
    "#\n",
    "orb_features = feat.load(configs.orb, None)\n",
    "orb_bovw = vw.load_bovw(configs.orb_bovw, None)\n",
    "\n",
    "print(\"ORB features:\", orb_features.features.shape)\n",
    "print(\"ORB BoVW clusters:\", orb_bovw.cluster_centers.shape)\n",
    "print()\n",
    "\n",
    "\n",
    "#\n",
    "# sift\n",
    "#\n",
    "sift_features = feat.load(configs.sift, None)\n",
    "sift_bovw = vw.load_bovw(configs.sift_bovw, None)\n",
    "\n",
    "print(\"Sift features:\", sift_features.features.shape)\n",
    "print(\"Sift BoVW clusters:\", sift_bovw.cluster_centers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8834a41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# export en batch des visual words orb\n",
    "#\n",
    "\n",
    "# pour debugger, s'assurer que le fichier de visual words \n",
    "# est detruit a chaque execution de la cellule\n",
    "if \"orb_pv_vw\" in locals():\n",
    "    del orb_pv_vw\n",
    "\n",
    "with hlp.Profile() as orb_pv_vw_loading:\n",
    "    orb_pv_vw = vw.load_dataset_vw(configs.orb_dataset_vw,\n",
    "                                   orb_features,\n",
    "                                   configs.orb_bovw,\n",
    "                                   orb_bovw,\n",
    "                                   train,\n",
    "                                   test)\n",
    "    \n",
    "print(f\"ORB PlantVillage Visual Word loading:\", orb_pv_vw_loading.round_duration(), \"s\")\n",
    "print(\"ORB PlantVillage Visual Words\", orb_pv_vw.vw_freqs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e031ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.ravel( orb_bovw.idf )\n",
    "# b = np.ravel( orb_pv_vw.index_to_vw_freqs[\"46984\"] )\n",
    "# c = np.multiply(a, b)\n",
    "\n",
    "# plt.figure( figsize=(10, 6) )\n",
    "\n",
    "# plt.subplot(311)\n",
    "# plt.title(\"idf\")\n",
    "# plt.bar(range(500), a)\n",
    "\n",
    "# plt.subplot(312)\n",
    "# plt.title(\"tf\")\n",
    "# plt.bar(range(500), b)\n",
    "\n",
    "# plt.subplot(313)\n",
    "# plt.title(\"tf-idf\")\n",
    "# plt.bar(range(500), c)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b80e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# export en batch des visual words sift\n",
    "#\n",
    "\n",
    "# pour debugger, s'assurer que le fichier de visual words \n",
    "# est detruit a chaque execution de la cellule\n",
    "if \"sift_pv_vw\" in locals():\n",
    "    del sift_pv_vw\n",
    "\n",
    "with hlp.Profile() as sift_pv_vw_loading:\n",
    "    sift_pv_vw = vw.load_dataset_vw(configs.sift_dataset_vw, \n",
    "                                    sift_features,\n",
    "                                    configs.sift_bovw,\n",
    "                                    sift_bovw,\n",
    "                                    train,\n",
    "                                    test)\n",
    "\n",
    "print(f\"sift PlantVillage Visual Word loading:\", sift_pv_vw_loading.round_duration(), \"s\")\n",
    "print(\"sift PlantVillage Visual Words\", sift_pv_vw.vw_freqs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87894c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES_GRID = (4, 2)\n",
    "SAMPLES_COUNT = SAMPLES_GRID[0]\n",
    "FIGSIZE = (10, SAMPLES_GRID[0] * 2.5)\n",
    "\n",
    "def affiche_image(image_indices, bovw, features, pv_vw):\n",
    "    x_range = range(bovw.cluster_centers.shape[0])\n",
    "    idf = np.ravel(bovw.idf)\n",
    "    \n",
    "    figure, axes = plt.subplots(SAMPLES_GRID[0],\n",
    "                                SAMPLES_GRID[1],\n",
    "                                figsize=FIGSIZE,\n",
    "                                width_ratios=[1, 3])\n",
    "\n",
    "    for i, image_index in enumerate(image_indices):\n",
    "        key_points = features.index_to_key_points[str(image_index)][...]\n",
    "        visual_words_freq = pv_vw.index_to_vw_freqs[str(image_index)][...].flatten()\n",
    "        tf_idf = np.multiply(idf, visual_words_freq)\n",
    "\n",
    "        image = pv_dataset.get_image(image_index)\n",
    "        image_key_points = feat.draw_key_points(image, key_points)\n",
    "\n",
    "        species, disease = pv_dataframe.loc[image_index, [\"species\", \"disease\"]]\n",
    "        disease = pv.attribute_prettify(species, disease)\n",
    "        title = \"\\n\".join([species, disease])\n",
    "\n",
    "        plt.sca(axes[i, 0])\n",
    "        plt.gca().set_ylabel(title)\n",
    "        plt.gca().set_xticks([])\n",
    "        plt.gca().set_yticks([])\n",
    "        plt.imshow(image_key_points)\n",
    "\n",
    "        plt.sca(axes[i, 1])\n",
    "        plt.bar(x_range, tf_idf)\n",
    "\n",
    "    axes[0, 0].set_title(\"Key Points\")\n",
    "    axes[0, 1].set_title(\"tf-idf Visual Words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffda4cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selectionner quelques images aleatoirement\n",
    "random.seed(33)\n",
    "image_indices = random.choices(train, k=SAMPLES_COUNT)\n",
    "image_indices.sort()\n",
    "\n",
    "#\n",
    "# visualiser quelques visual words orb\n",
    "#\n",
    "affiche_image(image_indices,\n",
    "              orb_bovw,\n",
    "              orb_features, \n",
    "              orb_pv_vw)\n",
    "\n",
    "plt.suptitle(\"ORB\")\n",
    "plt.tight_layout()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576048a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# visualiser quelques visual words sift (memes que orb)\n",
    "#\n",
    "affiche_image(image_indices,\n",
    "              sift_bovw,\n",
    "              sift_features, \n",
    "              sift_pv_vw)\n",
    "\n",
    "plt.suptitle(\"SIFT\")\n",
    "plt.tight_layout()\n",
    "plt.show() \n",
    "    \n",
    "# figure.savefig(f\"{vw_title}_visual_words.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafc5e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#\n",
    "# import utilitaires\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "import helpers as hlp\n",
    "import helpers.features as feat\n",
    "import helpers.dataset.PlantVillage as pv\n",
    "import helpers.split as split\n",
    "import helpers.visual_words as vw\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans, DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import accuracy_score, \\\n",
    "    f1_score, \\\n",
    "    confusion_matrix, \\\n",
    "    ConfusionMatrixDisplay, \\\n",
    "    calinski_harabasz_score, \\\n",
    "    davies_bouldin_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# enlever FutureWarning de sklearn \n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfd3dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# parametres\n",
    "#\n",
    "configs = hlp.get_configs(\"config_overrides.json\")\n",
    "\n",
    "\n",
    "#\n",
    "# train/test sets\n",
    "# \n",
    "train, test = split.load(configs.split)\n",
    "print(\"Train size\", len(train))\n",
    "print(\"Test size\", len(test))\n",
    "\n",
    "\n",
    "#\n",
    "# dataset PlantVillage\n",
    "#\n",
    "pv_dataset = pv.load(configs.plant_village)\n",
    "pv_dataframe = pv_dataset.dataframe\n",
    "\n",
    "print(\"Dataset\", pv_dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed405d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# features sift\n",
    "#\n",
    "\n",
    "configs.sift.force_generate = True\n",
    "configs.sift.read_only = False\n",
    "\n",
    "if \"sift_features\" in locals():\n",
    "    del sift_features\n",
    "\n",
    "with hlp.Profile() as sift_loading:\n",
    "    #\n",
    "    # obtenir les sift features pour chaque image du dataset\n",
    "    #\n",
    "    sift_iter = feat.DatasetIter(pv_dataset, \n",
    "                                 pv_dataframe.loc[train + test, \"image_path\"].items(),\n",
    "                                 len(train + test))\n",
    "    sift_features = feat.load(configs.sift, sift_iter)\n",
    "\n",
    "print(f\"SIFT loading:\", sift_loading.round_duration(), \"s\")\n",
    "print(\"SIFT keypoints\", sift_features.key_points.shape)\n",
    "print(\"SIFT features\", sift_features.features.shape)\n",
    "\n",
    "if configs.sift.force_generate or sift_features.train_features is None:\n",
    "    feat.update_train_test(sift_features, train, test)\n",
    "\n",
    "print(\"SIFT train features\", sift_features.train_features.shape)\n",
    "print(\"SIFT test features\", sift_features.test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66f34f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# reduction des features (voir notebook precedant pour savoir combien de component on garde sur SIFT)\n",
    "#\n",
    "\n",
    "pca_pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"pca\", PCA(n_components=configs.sift_bovw.pca_n_components, svd_solver=\"full\", random_state=42))\n",
    "     ])\n",
    "sift_train_features_pca = pca_pipe.fit_transform(sift_features.train_features);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd47c53",
   "metadata": {},
   "source": [
    "La litérature est relativement large sur le sujet des clusters. En effet, les techniques de regorupement par densité, par hiéarchie et distance sont toutes explorées. Cependant, nos expérimentations nous ont montrées que seul **MiniBatchKMeans** converge. En effet DBSCAN, SpectralClustering et autres ne terminent pas dans un temps raisonable ou crash tout simplement.\n",
    "\n",
    "Il est difficile d'évaluer visuellement la qualité de notre clustering etant donné la dimentionalité de nos données. PCA et TSNE ne nous montrent pas un regroupement clair. Nous avons donc opté pour une approche plus simple. A savoir des clusters compactes quitte à avoir beaucoup de chevauchement. Nos métriques sont donc l'inertie (graphe en coude) et **skelarn.metrics.davies_bouldin_score** (recherche valeur minimale). \n",
    "\n",
    "* Mettre note pour epliquer **davies_bouldin_score**.\n",
    "* https://scikit-learn.org/stable/modules/clustering.html#clustering-evaluation\n",
    "* https://towardsdatascience.com/cheat-sheet-to-implementing-7-methods-for-selecting-optimal-number-of-clusters-in-python-898241e1d6ad\n",
    "* Est-ce que resampler les features auraient du etre fait? Voir graphes et notes dans [06 - Training - Analyse et recommendations](<06 - Training - Analyse et recommendations.ipynb>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81216c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_range = range(55, 501, 10)\n",
    "cluster_scores = [[],[]]\n",
    "for n_clusters in tqdm(cluster_range):\n",
    "    cluster_model = MiniBatchKMeans(n_clusters=n_clusters,\n",
    "                                    batch_size=256 * 12,\n",
    "                                    random_state=42,\n",
    "                                    n_init=\"auto\")\n",
    "    cluster_labels = cluster_model.fit_predict(sift_train_features_pca)\n",
    "\n",
    "    # mesure la similarite entre les clusters; lower is better\n",
    "    david_boutin = davies_bouldin_score(sift_train_features_pca, cluster_labels)\n",
    "\n",
    "    # pour trouver un coude\n",
    "    inertia = cluster_model.inertia_\n",
    "\n",
    "    # prendre en note les mesures\n",
    "    cluster_scores[0].append(david_boutin)\n",
    "    cluster_scores[1].append(inertia)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "# afficher les mesures\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title(\"davies_bouldin_score\")\n",
    "plt.plot(cluster_range, cluster_scores[0], marker=\".\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title(\"Model inertia\")\n",
    "plt.plot(cluster_range, cluster_scores[1], marker=\".\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5892234f",
   "metadata": {},
   "source": [
    "D'après le graphe ci-haut, un bon nombre de clusters serait dans l'interval 100 à 200: minimum marqué par davies_bouldin_score et l'inflexion dans le diagrame de l'inertie semble devenir plutôt linéaire. Notre choix s'arrête donc sur 175. Cette information sera intégrée via nos fichiers de configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30849d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# bovw sift\n",
    "#\n",
    "\n",
    "configs.sift_bovw.force_generate = True\n",
    "\n",
    "if \"sift_bovw\" in locals():\n",
    "    del sift_bovw\n",
    "\n",
    "# soyez patient, ce n'est pas interactif\n",
    "with hlp.Profile() as sift_bovw_profile:\n",
    "    sift_bovw = vw.load_bovw(configs.sift_bovw, sift_features.train_features)\n",
    "\n",
    "print(\"SIFT BoVW loading:\", sift_bovw_profile.round_duration(), \"s\")\n",
    "print(\"SIFT BoVW clusters:\", sift_bovw.cluster_centers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0362b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# dataset vw sift\n",
    "#\n",
    "\n",
    "configs.sift_dataset_vw.force_generate = True\n",
    "\n",
    "if \"sift_pv_vw\" in locals():\n",
    "    del sift_pv_vw\n",
    "\n",
    "with hlp.Profile() as sift_pv_vw_loading:\n",
    "    sift_pv_vw = vw.load_dataset_vw(configs.sift_dataset_vw,\n",
    "                                   sift_features,\n",
    "                                   configs.sift_bovw,\n",
    "                                   sift_bovw,\n",
    "                                   train,\n",
    "                                   test)\n",
    "    \n",
    "print(f\"SIFT PlantVillage Visual Word loading:\", sift_pv_vw_loading.round_duration(), \"s\")\n",
    "print(\"SIFT PlantVillage Visual Words\", sift_pv_vw.vw_freqs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafcf7cf",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "# visualiser quelques visual words sift\n",
    "#\n",
    "\n",
    "SAMPLES_GRID = (4, 2)\n",
    "SAMPLES_COUNT = SAMPLES_GRID[0]\n",
    "FIGSIZE = (10, SAMPLES_GRID[0] * 2.5)\n",
    "\n",
    "def affiche_vw(image_indices, bovw, features, pv_vw):\n",
    "    x_range = range(bovw.cluster_centers.shape[0])\n",
    "    idf = np.ravel(bovw.idf)\n",
    "    \n",
    "    figure, axes = plt.subplots(SAMPLES_GRID[0],\n",
    "                                SAMPLES_GRID[1],\n",
    "                                figsize=FIGSIZE,\n",
    "                                width_ratios=[1, 3])\n",
    "\n",
    "    for i, image_index in enumerate(image_indices):\n",
    "        key_points = features.index_to_key_points[str(image_index)][...]\n",
    "        visual_words_freq = pv_vw.index_to_vw_freqs[str(image_index)][...].flatten()\n",
    "        tf_idf = np.multiply(idf, visual_words_freq)\n",
    "\n",
    "        image = pv_dataset.get_image(image_index)\n",
    "        image_key_points = feat.draw_key_points(image, key_points)\n",
    "\n",
    "        species, disease = pv_dataframe.loc[image_index, [\"species\", \"disease\"]]\n",
    "        disease = pv.attribute_prettify(species, disease)\n",
    "        title = \"\\n\".join([species, disease])\n",
    "\n",
    "        plt.sca(axes[i, 0])\n",
    "        plt.gca().set_ylabel(title)\n",
    "        plt.gca().set_xticks([])\n",
    "        plt.gca().set_yticks([])\n",
    "        plt.imshow(image_key_points)\n",
    "\n",
    "        plt.sca(axes[i, 1])\n",
    "        plt.bar(x_range, tf_idf)\n",
    "\n",
    "    axes[0, 0].set_title(\"Key Points\")\n",
    "    axes[0, 1].set_title(\"tf-idf Visual Words\")\n",
    "    \n",
    "\n",
    "# selectionner quelques images aleatoirement\n",
    "random.seed(55)\n",
    "image_indices = random.choices(train, k=SAMPLES_COUNT)\n",
    "image_indices.sort()\n",
    "\n",
    "affiche_vw(image_indices,\n",
    "           sift_bovw,\n",
    "           sift_features, \n",
    "           sift_pv_vw)\n",
    "\n",
    "plt.suptitle(\"SIFT\")\n",
    "plt.tight_layout()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213570f1",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "# mettre le data dans une forme acceptable pour sklearn\n",
    "#\n",
    "train_y = pv_dataframe.loc[train, \"label\"]\n",
    "test_y = pv_dataframe.loc[test, \"label\"]\n",
    "\n",
    "# sift_pv_vw* garantissent l'ordre donne par train/test lors de l'etape precedante \n",
    "# alors faire gaffe a ne pas le changer\n",
    "sift_train_x = np.multiply(sift_pv_vw.train_vw_freqs[...], sift_bovw.idf)\n",
    "sift_test_x = np.multiply(sift_pv_vw.test_vw_freqs[...], sift_bovw.idf)\n",
    "\n",
    "assert sift_train_x.shape[0] == train_y.shape[0]\n",
    "assert sift_test_x.shape[0] == test_y.shape[0]\n",
    "\n",
    "print(\"SIFT PlantVillage train Visual Words\", sift_train_x.shape)\n",
    "print(\"SIFT PlantVillage test Visual Words\", sift_test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6d499e",
   "metadata": {},
   "source": [
    "Validation de **sift_train_x** juste avant la classification. On veut s'assurer qu'il y ait très peu de corrélation entre les featues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4af9781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose parce que numpy veux les variables dans les rangees\n",
    "corr = np.corrcoef( sift_train_x.T )\n",
    "\n",
    "# enlever 1 et -1\n",
    "corr_no_one = np.where(np.isclose(corr, 1), 0, corr)\n",
    "corr_max = np.max(corr_no_one)\n",
    "corr_min = np.min(corr_no_one)\n",
    "\n",
    "CORR_THRESHOLD = 0.6\n",
    "corr_thresholded = np.where(abs(corr) > CORR_THRESHOLD, corr, 0)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(121)\n",
    "sns.heatmap(corr, cbar=False)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title(f\"corrélation > abs({CORR_THRESHOLD})\")\n",
    "sns.heatmap(corr_thresholded, cbar=False)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "plt.suptitle(f\"Corrélation heatmap {corr.shape}\\nmin: {round(corr_min, 3)}, max: {round(corr_max, 3)}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbce48a9",
   "metadata": {
    "code_folding": [
     0,
     42
    ]
   },
   "outputs": [],
   "source": [
    "def load_knn(model_filename, train_x, train_y):\n",
    "    \"\"\"\n",
    "    Utilitaire pour entrainer un model et le serialiser\n",
    "    \"\"\"\n",
    "    if False and os.path.exists(model_filename):\n",
    "        # charger le modele pre-entrainer\n",
    "        with open(model_filename, \"rb\") as file:\n",
    "            pipe = pickle.load(file)\n",
    "    else:\n",
    "        # trouver meilleurs parametres pour n_neighbors\n",
    "        CROSS_VALIDATION_FOLDS = 5\n",
    "        \n",
    "        pipe = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                         (\"knn\", KNeighborsClassifier(n_jobs=-1))])\n",
    "\n",
    "        pipe_parameters = {\"knn__n_neighbors\": range(1, 5),\n",
    "                           \"knn__weights\": [\"uniform\", \"distance\"]}\n",
    "\n",
    "        grid_search = GridSearchCV(pipe, \n",
    "                                  pipe_parameters, \n",
    "                                  scoring=\"accuracy\",\n",
    "                                  refit=True,\n",
    "                                  cv=CROSS_VALIDATION_FOLDS)\n",
    "\n",
    "        with hlp.Profile() as grid_search_time:\n",
    "            grid_search.fit(train_x, train_y)\n",
    "\n",
    "        # sauvegarde du meilleur modele knn\n",
    "        pipe = grid_search.best_estimator_\n",
    "        head, _ = os.path.split(model_filename)\n",
    "        os.makedirs(head, exist_ok=True)\n",
    "        with open(model_filename, \"wb\") as file:\n",
    "            pickle.dump(pipe, file)\n",
    "\n",
    "        # afficher quelques stats\n",
    "        print(\"Search time:\", grid_search_time.round_duration(), \"s\")\n",
    "        print(\"Best params\", grid_search.best_params_)\n",
    "        print(\"Train score:\", grid_search.best_score_.round(4))\n",
    "        print()\n",
    "            \n",
    "    return pipe\n",
    "\n",
    "def analysis_knn(method_name, pipe, test_x, test_y):\n",
    "    test_y_hat = pipe.predict(test_x)\n",
    "\n",
    "    print(method_name, \"KNN n_neighbors:\", pipe.named_steps[\"knn\"].n_neighbors)\n",
    "    print(method_name, \"KNN test score:\", accuracy_score(test_y, test_y_hat).round(4))\n",
    "    print(method_name, \"KNN f1 score:\", f1_score(test_y, test_y_hat, average=\"micro\").round(4))\n",
    "    print()\n",
    "    print(\"Effectifs test set:\")\n",
    "    print( test_y.value_counts() )\n",
    "\n",
    "    # confusion matrix\n",
    "    plt.figure(figsize=(5, 4))\n",
    "\n",
    "    cm = confusion_matrix(test_y, test_y_hat)\n",
    "    cmd = ConfusionMatrixDisplay(cm, display_labels=pipe.classes_)\n",
    "    cmd.plot(ax=plt.gca())\n",
    "    cmd.im_.colorbar.remove()\n",
    "\n",
    "    plt.title(f\"{method_name} - KNN - Confusion matrix\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "\n",
    "#\n",
    "# SIFT KNN\n",
    "#\n",
    "sift_knn_pipe = load_knn(\"models/sift_knn.pkl\", sift_train_x, train_y)\n",
    "analysis_knn(\"SIFT\", sift_knn_pipe, sift_test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716b2889",
   "metadata": {
    "code_folding": [
     42
    ]
   },
   "outputs": [],
   "source": [
    "def load_rf(model_filename, train_x, train_y):\n",
    "    \"\"\"\n",
    "    Utilitaire pour entrainer un model et le serialiser\n",
    "    \"\"\"\n",
    "    if False and os.path.exists(model_filename):\n",
    "        # charger le modele pre-entrainer\n",
    "        with open(model_filename, \"rb\") as file:\n",
    "            pipe = pickle.load(file)\n",
    "    else:\n",
    "        # trouver meilleurs parametres pour n_neighbors\n",
    "        CROSS_VALIDATION_FOLDS = 5\n",
    "\n",
    "        pipe = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                         (\"forest_gump\", RandomForestClassifier(random_state=42, n_jobs=-1))])\n",
    "\n",
    "        pipe_parameters = {\"forest_gump__n_estimators\": range(50, 200)}\n",
    "\n",
    "        grid_search = GridSearchCV(pipe, \n",
    "                                  pipe_parameters, \n",
    "                                  scoring=\"accuracy\",\n",
    "                                  refit=True,\n",
    "                                  cv=CROSS_VALIDATION_FOLDS,\n",
    "                                  n_jobs=-1)\n",
    "\n",
    "        with hlp.Profile() as grid_search_time:\n",
    "            grid_search.fit(train_x, train_y)\n",
    "\n",
    "        # sauvegarde du meilleur modele knn\n",
    "        pipe = grid_search.best_estimator_\n",
    "        head, _ = os.path.split(model_filename)\n",
    "        os.makedirs(head, exist_ok=True)\n",
    "        with open(model_filename, \"wb\") as file:\n",
    "            pickle.dump(pipe, file)\n",
    "\n",
    "        # afficher quelques stats\n",
    "        print(\"Search time:\", grid_search_time.round_duration(), \"s\")\n",
    "        print(\"Best params\", grid_search.best_params_)\n",
    "        print(\"Train score:\", grid_search.best_score_.round(4))\n",
    "        print()\n",
    "            \n",
    "    return pipe\n",
    "\n",
    "def analysis_rf(method_name, pipe, test_x, test_y):\n",
    "    test_y_hat = pipe.predict(test_x)\n",
    "\n",
    "    print(method_name, \"Random Forest n_estimators:\", pipe.named_steps[\"forest_gump\"].n_estimators)\n",
    "    print(method_name, \"Random Forest test score:\", accuracy_score(test_y, test_y_hat).round(4))\n",
    "    print(method_name, \"Random f1 score:\", f1_score(test_y, test_y_hat, average=\"micro\").round(4))\n",
    "    print()\n",
    "    print(\"Effectifs test set:\")\n",
    "    print( test_y.value_counts() )\n",
    "\n",
    "    # confusion matrix\n",
    "    plt.figure(figsize=(5, 4))\n",
    "\n",
    "    cm = confusion_matrix(test_y, test_y_hat)\n",
    "    cmd = ConfusionMatrixDisplay(cm, display_labels=pipe.classes_)\n",
    "    cmd.plot(ax=plt.gca())\n",
    "    cmd.im_.colorbar.remove()\n",
    "\n",
    "    plt.title(f\"{method_name} - Random Forest - Confusion matrix\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "#\n",
    "# SIFT Random Forest\n",
    "#\n",
    "sift_rf_pipe = load_rf(\"models/sift_random_forest.pkl\", sift_train_x, train_y)\n",
    "analysis_rf(\"SIFT\", sift_rf_pipe, sift_test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a4bd1b",
   "metadata": {},
   "source": [
    "# Annexe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a91e86f",
   "metadata": {},
   "source": [
    "<font class=\"answer\">\n",
    "    \n",
    "Les objectifs secondaires de ce projet étaient d'abord se familiariser avec des données un peu plus complexes par leur volumes et par leur nature puis d'adresser le travail collaboratif. En effet, en milieu de travail ou non, le partage de résultats et le temps d'itération sont des facteurs déterminant pour le succès. Cette section détaillera les solutions que nous proposons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b898ff",
   "metadata": {},
   "source": [
    "## Organisation du travail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd1d75e",
   "metadata": {},
   "source": [
    "<font class=\"answer\">\n",
    "\n",
    "Notre approche à haut niveau s'apparente à un \"pipeline\": chaque coéquipier se concentre sur une étape et produit un fichier qui pourra être consommé par l'étape suivante. Ceci permet de decoupler les tâches afin de travailer en parralèle.\n",
    "\n",
    "Des modules python permettent de définir les interface de chaque étapes (et d'éviter la duplication d'information) ainsi que les opérations nécessaire. Un effet secondaire bénifique de cette approche est la configurabilité: aucun code n'a besoin d'être modifié pour expérimenter, seulement les paramètres exposés par les interfaces. Dans un but de centralisation, ces paramètres sont exposés à travers un fichier .json (config_overrides.json). Finalement git est utilisé pour suivre l'évolution et communiquer les changements à toute l'équipe.\n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"columns_2\">\n",
    "Structure des fichiers\n",
    "<img src=\"images/structure_fichiers.png\" width=\"50%\">\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"columns_2\">\n",
    "Structure des modules python\n",
    "<img src=\"images/modules_python.png\" width=\"35%\">\n",
    "</div>\n",
    "    \n",
    "    \n",
    "| Module python | Responsabilité |\n",
    "|--|:--|\n",
    "| helpers| Encapsulation des fonctionalités communes (multithreading, configurations, affichage) |\n",
    "| dataset/PlantVillage| Encapsupation de la base de données. S'occupe du prétraitement et d'obtenir les pixels des images |\n",
    "| features | Encapsulation du traitement fait sur les images (l'extraction des keypoints et descripteurs, etc) |\n",
    "| visual_words | Encapsulation de tout ce qui touche au dictionnaire (conversion des descripteurs, histograme) |\n",
    "| split | Encapsulation de l'information des ensembles d'entraînement et test |        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4784bc4",
   "metadata": {},
   "source": [
    "## Reproductibilité des résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fcb8a1",
   "metadata": {},
   "source": [
    "<font class=\"answer\">\n",
    "    \n",
    "Il nous apparait important de s'assurer que toute personnes voulant reproduire les résultats puissent le faire sans trop se soucier des détails d'implémentations. Chaque interface intégre ce concept en augmentant le fichier .json pour automatiser son processus interne et en mettant en cache les résultats pertinants. Par exemple, le module dataset/PlantVillage s'occupe du téléchargement de la base de données et du prétraitement lors de la première execution. L'utilisateur n'a pas à se soucier de rien: il obtiendra toujours un dataframe formater de la même manière. Exemple de configuration:\n",
    "    \n",
    "```json\n",
    "\"dataset\": {\n",
    "    \"url\": \"https://tinyurl.com/22tas3na\",\n",
    "    \"install_path\": \"dataset/PlantVillage.hd5\"\n",
    "}\n",
    "```\n",
    "    \n",
    "Le contrôle de l'environment de dévelopmement est également important. Nous avons adressé ce problème avec les environments d'Anaconda et python. *conda_requirements.yaml* et *requirements.txt* listent les diverses libraires utilisées et leurs versions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c73cc76",
   "metadata": {},
   "source": [
    "## Temps d'itération"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3650d796",
   "metadata": {},
   "source": [
    "<font class=\"answer\">\n",
    "\n",
    "Une partie de la complexité de notre projet tente d'adresser le temps d'itération. En effet, une itération naîve peut devenir très problématique lorque nous avons à manipuler des millions d'éléments. Nous avons adressé ce problème sur deux fronts: le multithreading pour l'aspect calcul de résultats et le format HDF5 pour la persistence de ceux-ci.\n",
    "    \n",
    "Malgré les considérations apportées, nous avons tout de même dû minimiser la quantité d'éléments à traiter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d3c3b1",
   "metadata": {},
   "source": [
    "### Multithreading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7752fa8",
   "metadata": {},
   "source": [
    "<font class=\"answer\">\n",
    "    \n",
    "    \n",
    "A titre d'exemple, l'extraction des keypoints et des descripteurs est passé de ~60s à ~20s.\n",
    "La conversion des images en visual words est passer de 11s à ~9s\n",
    "    \n",
    "Un facteur limitant est le GIL de python. En effet, par design, python \n",
    "    \n",
    "Parler de Concurent et les batch process, multithreading et GIL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79571077",
   "metadata": {},
   "source": [
    "### HDF5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87aa80e",
   "metadata": {},
   "source": [
    "<font class=\"answer\">\n",
    "Parler de"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
