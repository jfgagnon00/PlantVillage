Taches pour ce samedi
    Fred:
        * continue Segmentation
        * optimization size dictionaire

    Michele:
        * regarder comment comment on peut enlever de features a SIFT (reduire le 128)
            1 image == M x 128 (m descriptors, chaque desc a 128 floats)
                - mesure dependance entre quantitatif continue et label?
                    - https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest
                    - https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html

                - https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html
                    DecisionTreeClassifier()
                    RandomForest()

                - https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html

    JFG:
        * finir le notebook training

Objectifs:
    * Construire le dictionnaire
        - il faudrait starter analyse pour resampler et analyser les correlations entre features
        - investiguer visualisation pour aider a comprendre les correlations (t-sne)?
        - investiguer d'autres choix de features?
        - constuire les les visual words par image est etonnement long

    * Entrainer KNN et Random Forest

    * Sauvegarder des modeles

    * Wrapper dans "application" (widgets notebook?)

    * Optimization des hyperparametres (les valeurs qui sont dans config_overrides.json)
        * choix du type de features (ORB ou SIFT)
        * determiner nombre de features optimales
        * Ajouter un label 'Ca marche pas -  inclassifiable'

    * Evaluer

    * Rapport + presentation

Stretch goal:
    * Segmentation background/foreground pour feature extraction
    * Size optimal pour dictionnaire (trouver algo et resampler features)
    * TF-IDF pour l'histogramme
    * Passer SIFT Features en half float si besoin
    * Enlever thumnails
